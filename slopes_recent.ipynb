{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SB(X,y):\n",
    "     return np.polyfit(X,y,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 25\n",
    "epsilon = 0.25\n",
    "e_frequency = 1\n",
    "r = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring the slope\n",
    "# highest probability for each complexity value np.polyfit\n",
    "# start_iteration 0,1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the slope\n",
    "highest probability for each complexity value np.polyfit\n",
    "start_iteration 0,1000\n",
    "epsilon_freq = 1\n",
    "epsilon = [0.01 .... 0.6]\n",
    "r=1,2,3,3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS\n",
    "SAMPLES = 10**5\n",
    "from KC_methods import calc_KC78\n",
    "# Generate figure for each epsilon value\n",
    "import pandas as pd\n",
    "from logistic_maps import generate_logistic\n",
    "\n",
    "epsilon = 0.2\n",
    "e_frequency = 1\n",
    "r = 4\n",
    "\n",
    "patterns = generate_logistic(n_iterations,start_iteration=1000,epsilon=epsilon,e_frequency=e_frequency,r=r)\n",
    "probability = Counter(patterns)\n",
    "probability = {k: v/SAMPLES for k,v in probability.items()}\n",
    "\n",
    "probability_values =  list(probability.values())\n",
    "complexities = list(map(calc_KC78,probability.keys()))\n",
    "\n",
    "df = pd.DataFrame({\"y\":probability_values,'x':complexities})\n",
    "plt.scatter(df[\"x\"],df[\"y\"])\n",
    "\n",
    "groupmax = df.groupby('x').max().reset_index()\n",
    "ar = calc_SB(groupmax['x'],np.log10(groupmax['y']))#\n",
    "slope = ar[0]\n",
    "print(slope)\n",
    "plt.title(f\"r={r},e={epsilon},{e_frequency=},slope={slope:.2f}\")\n",
    "# trendpoly = np.poly1d(ar) \n",
    "# print([start_iteration,epsilon,e_frequency,r,slope])\n",
    "# results.append([start_iteration,epsilon,e_frequency,r,slope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pybdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Digital Garden\\Research\\logistic_map_simplicity_bias\\slopes_recent.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Digital%20Garden/Research/logistic_map_simplicity_bias/slopes_recent.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m SAMPLES \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Digital%20Garden/Research/logistic_map_simplicity_bias/slopes_recent.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mKC_methods\u001b[39;00m \u001b[39mimport\u001b[39;00m calc_KC78\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Digital%20Garden/Research/logistic_map_simplicity_bias/slopes_recent.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Generate figure for each epsilon value\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Digital%20Garden/Research/logistic_map_simplicity_bias/slopes_recent.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[1;32md:\\Digital Garden\\Research\\logistic_map_simplicity_bias\\KC_methods.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpybdm\u001b[39;00m \u001b[39mimport\u001b[39;00m BDM\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pybdm'"
     ]
    }
   ],
   "source": [
    "SAMPLES = 10**5\n",
    "from KC_methods import calc_KC78\n",
    "# Generate figure for each epsilon value\n",
    "import pandas as pd\n",
    "from logistic_maps import generate_logistic\n",
    "results = []\n",
    "for start_iteration in [0,1000]:\n",
    "    for epsilon in [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "        for r in [-1,0.5,1,1.5,2.0,2.5,3,3.5,4]:\n",
    "            e_frequency = 1\n",
    "            if epsilon == 0:\n",
    "                e_frequency = 0\n",
    "            patterns = generate_logistic(n_iterations,start_iteration=start_iteration,epsilon=epsilon,e_frequency=e_frequency,r=r)\n",
    "            probability = Counter(patterns)\n",
    "            probability = {k: v/SAMPLES for k,v in probability.items()}\n",
    "\n",
    "            probability_values =  list(probability.values())\n",
    "            complexities = list(map(calc_KC78,probability.keys()))\n",
    "\n",
    "            df = pd.DataFrame({\"y\":probability_values,'x':complexities})\n",
    "            groupmax = df.groupby('x').max().reset_index()\n",
    "            ar = calc_SB(groupmax['x'],np.log10(groupmax['y']))\n",
    "            slope = ar[0]\n",
    "            # K_scaled = df[\"x\"]\n",
    "            # if len(K_scaled) >1:\n",
    "            #     K_scaled = n_iterations * ( K_scaled-min(K_scaled) ) / ( max(K_scaled)-min(K_scaled) )\n",
    "\n",
    "            trendpoly = np.poly1d(ar) \n",
    "            print([start_iteration,epsilon,e_frequency,r,slope])\n",
    "            results.append([start_iteration,epsilon,e_frequency,r,slope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"slopesssss_1000.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b24365a9e581578216d0d29db6b7b60d5f38a355f07d5a2e870dec36c1112eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
